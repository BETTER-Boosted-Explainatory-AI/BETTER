from fastapi import HTTPException, status
import os
from .dataset_service import _get_dataset_config, _load_dataset
from .models_service import _load_model, _get_model_path
from utilss.classes.nma import NMA
from utilss.classes.edges_dataframe import EdgesDataframe
from utilss.classes.dendrogram import Dendrogram
from utilss.enums.datasets_enum import DatasetsEnum
from utilss.enums.graph_types import GraphTypes
from utilss.files_utils import update_current_model
import os
import boto3
from utilss.s3_utils import get_users_s3_client, get_datasets_s3_client
import json
import numpy as np
        
import logging
logger = logging.getLogger(__name__)

### original implemetation ###
# def _create_nma(model_file, graph_type, dataset_str, user, min_confidence, top_k, model_id_md):
#     if model_file is None:
#         raise HTTPException(
#             status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, 
#             detail="Model file is required"
#         )
        
#     if graph_type != GraphTypes.SIMILARITY.value and graph_type != GraphTypes.DISSIMILARITY.value and graph_type != GraphTypes.COUNT.value:
#         raise HTTPException(
#             status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, 
#             detail="Graph type must be either 'similarity' or 'dissimilarity'"
#         )
    
#     dataset_config = _get_dataset_config(dataset_str)
#     # dataset = _load_dataset(dataset_config)
#     dataset = _load_dataset(dataset_str)
    
#     try:
#         loaded_model = _load_model(dataset_str, model_file.name, dataset_config)
#         model_directory = _get_model_path(user.user_id, loaded_model.model_path)
#         if model_directory is None:
#             raise HTTPException(
#                 status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, 
#                 detail="Could not find model directory"
#             )
            
#         dataframe_filename = f'{model_directory}/{graph_type}/edges_df.csv'
#         dendrogram_filename = f'{model_directory}/{graph_type}/dendrogram'
        
#         labels = dataset.labels
#         if dataset_str == DatasetsEnum.IMAGENET.value:
#             labels = dataset.directory_labels

#         nma = NMA(
#             loaded_model.model,
#             dataset,
#             labels,
#             graph_type=graph_type,
#             top_k=top_k,
#             min_confidence=min_confidence           
#         )
        
#         edges_df_obj = EdgesDataframe(model_file.name, dataframe_filename, nma.edges_df)
#         edges_df_obj.save_dataframe()
#         print(nma.Z)            
        
#         dendrogram = Dendrogram(dendrogram_filename, nma.Z)
#         dendrogram._build_tree_hierarchy(nma.Z, dataset.labels)
        
#         dendrogram.save_dendrogram(nma.Z)
        
#         init_sub_z = dendrogram.get_sub_dendrogram_formatted(dataset_config["init_selected_labels"])
#         print(init_sub_z)

#         update_current_model(
#             user,
#             model_id_md,
#             graph_type,
#             model_file.filename,
#             dataset,
#             min_confidence,
#             top_k,
#         )
#         return init_sub_z
    
#     except Exception as e:
#         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


### S3 implementation ### 
# def _create_nma(model_path, graph_type, dataset_str, user, min_confidence, top_k, model_id_md):
#     if model_path is None:
#         raise HTTPException(
#             status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, 
#             detail="Model path is required"
#         )
        
#     if graph_type != GraphTypes.SIMILARITY.value and graph_type != GraphTypes.DISSIMILARITY.value and graph_type != GraphTypes.COUNT.value:
#         raise HTTPException(
#             status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, 
#             detail="Graph type must be either 'similarity', 'dissimilarity', or 'count'"
#         )
    
#     # Initialize S3 clients with correct credentials
#     users_s3_client = get_users_s3_client()
#     datasets_s3_client = get_datasets_s3_client()
    
#     s3_users_bucket = os.getenv("S3_USERS_BUCKET_NAME")
#     s3_datasets_bucket = os.getenv("S3_DATASETS_BUCKET_NAME")
    
#     if not s3_users_bucket:
#         raise ValueError("S3_USERS_BUCKET_NAME environment variable is required")
    
#     dataset_config = _get_dataset_config(dataset_str)
    
#     # Pass datasets client to dataset loader
#     dataset = _load_dataset(dataset_str)
    
#     try:
#         # Use users client for model loading
#         loaded_model = _load_model(dataset_str, model_path, dataset_config)
#         model_directory = _get_model_path(user.user_id, model_id_md)
        
#         if model_directory is None:
#             raise HTTPException(
#                 status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, 
#                 detail="Could not find model directory"
#             )
            
#         dataset.model_directory = model_directory    
#         # S3 paths for files
#         dataframe_filename = f'{model_directory}/{graph_type}/edges_df.csv'
#         dendrogram_filename = f'{model_directory}/{graph_type}/dendrogram'
        
#         labels = dataset.labels
#         if dataset_str == DatasetsEnum.IMAGENET.value:
#             labels = dataset.directory_labels

#         # Pass both clients to NMA
#         nma = NMA(
#             loaded_model.model,
#             dataset,
#             labels,
#             graph_type=graph_type,
#             top_k=top_k,
#             min_confidence=min_confidence,
#         )
        
#         s3_params = {
#             "s3_client": users_s3_client,
#             "s3_bucket": s3_users_bucket
#         }
        
#         # Create and save edges dataframe using users client
#         edges_df_obj = EdgesDataframe(model_path, dataframe_filename, nma.edges_df)
#         edges_df_obj.save_dataframe()
#         print(nma.Z)            
        
#         # Create and save dendrogram using users client
#         dendrogram = Dendrogram(dendrogram_filename, nma.Z)
#         dendrogram._build_tree_hierarchy(nma.Z, dataset.labels)
        
#         dendrogram.save_dendrogram(nma.Z)
        
#         # Convert init_selected_labels for ImageNet
#         if dataset_str == DatasetsEnum.IMAGENET.value:
#             # Create a mapping from human readable names to synset IDs
#             readable_to_synset = {}
            
#             try:
#                 # Load the synset mapping from S3
#                 mapping_key = "imagenet/train/LOC_synset_mapping.txt"
#                 response = datasets_s3_client.get_object(
#                     Bucket=s3_datasets_bucket, 
#                     Key=mapping_key
#                 )
#                 content = response['Body'].read().decode('utf-8')
                
#                 # Parse the mapping file: "n01440764 tench, Tinca tinca"
#                 for line in content.strip().split('\n'):
#                     if ' ' in line:
#                         synset, readable_names = line.split(' ', 1)
#                         # Split multiple names and clean them
#                         names = [name.strip() for name in readable_names.split(',')]
#                         for name in names:
#                             readable_to_synset[name] = synset
                
#                 logger.info(f"Loaded {len(readable_to_synset)} readable name mappings")
                
#                 # Convert init_selected_labels from readable names to synset IDs
#                 original_labels = dataset_config["init_selected_labels"]
#                 converted_labels = []
                
#                 for label in original_labels:
#                     if label in readable_to_synset:
#                         converted_labels.append(readable_to_synset[label])
#                         logger.info(f"Converted '{label}' -> '{readable_to_synset[label]}'")
#                     else:
#                         logger.warning(f"Could not find synset for '{label}', skipping")
                
#                 logger.info(f"Converted {len(converted_labels)} labels for ImageNet dendrogram")
#                 init_selected_labels = converted_labels
                
#             except Exception as e:
#                 logger.warning(f"Could not load synset mapping: {str(e)}, using first 5 synsets")
#                 # Fallback: use first 5 synsets from directory_labels
#                 init_selected_labels = dataset.directory_labels[:5]
#         else:
#             # For CIFAR-100, use labels as-is
#             init_selected_labels = dataset_config["init_selected_labels"]

#         init_sub_z = dendrogram.get_sub_dendrogram_formatted(init_selected_labels)
#         print(init_sub_z)

#         # âœ… Convert JSON to the format expected by NMAResult
#         init_sub_z_dict = json.loads(init_sub_z)

#         # Convert the nested dict structure to nested lists (recursive function)
#         def dict_to_nested_lists(obj):
#             if isinstance(obj, dict):
#                 # Convert dict to list of [key, value] pairs
#                 return [[k, dict_to_nested_lists(v)] for k, v in obj.items()]
#             elif isinstance(obj, list):
#                 return [dict_to_nested_lists(item) for item in obj]
#             else:
#                 return obj

#         # Convert to nested list structure
#         nested_list_structure = dict_to_nested_lists(init_sub_z_dict)
#         init_z_array = np.array([nested_list_structure], dtype=object)


#         # Extract filename from model_path
#         model_filename = os.path.basename(model_path)
#         update_current_model(
#             user,
#             model_id_md,
#             graph_type,
#             model_filename,
#             dataset,
#             min_confidence,
#             top_k,
#         )
#         return init_z_array 
    
#     except Exception as e:
#         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


def _create_nma(model_path, graph_type, dataset_str, user, min_confidence, top_k, model_id_md):
    if model_path is None:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, 
            detail="Model path is required"
        )
        
    if graph_type != GraphTypes.SIMILARITY.value and graph_type != GraphTypes.DISSIMILARITY.value and graph_type != GraphTypes.COUNT.value:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, 
            detail="Graph type must be either 'similarity', 'dissimilarity', or 'count'"
        )
    
    # Initialize S3 clients with correct credentials
    users_s3_client = get_users_s3_client()
    datasets_s3_client = get_datasets_s3_client()
    
    s3_users_bucket = os.getenv("S3_USERS_BUCKET_NAME")
    s3_datasets_bucket = os.getenv("S3_DATASETS_BUCKET_NAME")
    
    if not s3_users_bucket:
        raise ValueError("S3_USERS_BUCKET_NAME environment variable is required")
    
    dataset_config = _get_dataset_config(dataset_str)
    
    # Pass datasets client to dataset loader
    dataset = _load_dataset(dataset_str)
    
    try:
        # Use users client for model loading
        loaded_model = _load_model(dataset_str, model_path, dataset_config)
        model_directory = _get_model_path(user.user_id, model_id_md)
        
        if model_directory is None:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, 
                detail="Could not find model directory"
            )
            
        dataset.model_directory = model_directory    
        # S3 paths for files
        dataframe_filename = f'{model_directory}/{graph_type}/edges_df.csv'
        dendrogram_filename = f'{model_directory}/{graph_type}/dendrogram'
        
        labels = dataset.labels
        if dataset_str == DatasetsEnum.IMAGENET.value:
            labels = dataset.directory_labels

        # Pass both clients to NMA
        nma = NMA(
            loaded_model.model,
            dataset,
            labels,
            graph_type=graph_type,
            top_k=top_k,
            min_confidence=min_confidence,
        )
        
        s3_params = {
            "s3_client": users_s3_client,
            "s3_bucket": s3_users_bucket
        }
        
        # Create and save edges dataframe using users client
        edges_df_obj = EdgesDataframe(model_path, dataframe_filename, nma.edges_df)
        edges_df_obj.save_dataframe()
        print(nma.Z)            
        
        # Create and save dendrogram using users client
        dendrogram = Dendrogram(dendrogram_filename, nma.Z)
        dendrogram._build_tree_hierarchy(nma.Z, dataset.labels)
        
        dendrogram.save_dendrogram(nma.Z)
        
        # Convert init_selected_labels for ImageNet
        if dataset_str == DatasetsEnum.IMAGENET.value:
            # Create a mapping from human readable names to synset IDs
            readable_to_synset = {}
            
            try:
                # Load the synset mapping from S3
                mapping_key = "imagenet/train/LOC_synset_mapping.txt"
                response = datasets_s3_client.get_object(
                    Bucket=s3_datasets_bucket, 
                    Key=mapping_key
                )
                content = response['Body'].read().decode('utf-8')
                
                # Parse the mapping file: "n01440764 tench, Tinca tinca"
                for line in content.strip().split('\n'):
                    if ' ' in line:
                        synset, readable_names = line.split(' ', 1)
                        # Split multiple names and clean them
                        names = [name.strip() for name in readable_names.split(',')]
                        for name in names:
                            readable_to_synset[name] = synset
                
                logger.info(f"Loaded {len(readable_to_synset)} readable name mappings")
                
                # Convert init_selected_labels from readable names to synset IDs
                original_labels = dataset_config["init_selected_labels"]
                converted_labels = []
                
                for label in original_labels:
                    if label in readable_to_synset:
                        converted_labels.append(readable_to_synset[label])
                        logger.info(f"Converted '{label}' -> '{readable_to_synset[label]}'")
                    else:
                        logger.warning(f"Could not find synset for '{label}', skipping")
                
                logger.info(f"Converted {len(converted_labels)} labels for ImageNet dendrogram")
                init_selected_labels = converted_labels
                
            except Exception as e:
                logger.warning(f"Could not load synset mapping: {str(e)}, using first 5 synsets")
                # Fallback: use first 5 synsets from directory_labels
                init_selected_labels = dataset.directory_labels[:5]
        else:
            # For CIFAR-100, use labels as-is
            init_selected_labels = dataset_config["init_selected_labels"]

        init_sub_z = dendrogram.get_sub_dendrogram_formatted(init_selected_labels)
        print(init_sub_z)

        # ----- BEGIN FIXED CODE -----
        # Parse the JSON string into a Python dictionary
        init_sub_z_dict = json.loads(init_sub_z)
        
        # Convert hierarchical structure to flat list of lists of floats
        # This is the format expected by the NMAResult model
        flat_cluster_data = []
        
        def flatten_dendrogram(node, parent_id=-1.0, level=0.0):
            """
            Recursively flatten a hierarchical dendrogram structure into a list of float lists.
            Each list contains: [id, parent_id, level, value]
            """
            if not isinstance(node, dict):
                return
                
            # Extract node ID and value
            node_id = float(node.get('id', 0))
            node_value = float(node.get('value', 0.0))
            
            # Add this node as a row [id, parent_id, level, value]
            flat_cluster_data.append([node_id, parent_id, level, node_value])
            
            # Process children
            if 'children' in node and isinstance(node['children'], list):
                for child in node['children']:
                    flatten_dendrogram(child, node_id, level + 1.0)
        
        # Start the recursion from the root node
        flatten_dendrogram(init_sub_z_dict)
        
        # If no data was extracted, add a placeholder to avoid empty list error
        if not flat_cluster_data:
            # Add placeholder data if needed
            flat_cluster_data = [[0.0, 0.0, 0.0, 0.0]]
        
        # Save the original hierarchical structure to S3 for future reference
        hierarchy_path = f'{model_directory}/{graph_type}/hierarchy.json'
        users_s3_client.put_object(
            Body=init_sub_z,
            Bucket=s3_users_bucket,
            Key=hierarchy_path
        )
        
        logger.info(f"Flattened dendrogram to {len(flat_cluster_data)} data points")
        # ----- END FIXED CODE -----

        # Extract filename from model_path
        model_filename = os.path.basename(model_path)
        update_current_model(
            user,
            model_id_md,
            graph_type,
            model_filename,
            dataset,
            min_confidence,
            top_k,
        )
        
        # Return the flattened data structure
        return np.array(flat_cluster_data)
    
    except Exception as e:
        logger.error(f"Error in _create_nma: {str(e)}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))